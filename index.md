---
<!-- title: Deep Learning Made Easy -->
feature_image: "https://picsum.photos/1300/400?image=989"
feature_text: |
  ## Deep Learning Express
  A quick head start for deep learning starting from MLP to Transformers, BERT, and GPT-2!
---

<p><em>Through these 6 Google Colab notebooks you will learn necessary deep learning concepts and you will learn how to code deep learning models using PyTorch</em></p>

<hr>

<p><b>Notebook 1 (Key Concepts):</b> In this notebook you will learn the required deep learning (and ML) concepts before diving into the model architectures. These topics include: dataset spliting, forward propagation and backward propagation, optimizers, loss functions, activation functions, weight initialization, regularization, and normalization. </p>

  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1n0r1hAhpwdl8y68NunA2fxIRDyjBQJTF?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
  
 <hr>
 
<p><b>Notebook 2 (Multi-Layer Perceptron (MLP)):</b> In this notebook you will learn about the simplest deep learning model, the Multi-Layer Perceptron (MLP) network. </p>
<p style="color:#4863A0;"> If you want to do data visualization, data compression, encryption, or simple classification, MLP might be a good choice! </p>

  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1AGhp2rOU9_zo6mRwifNUSmbLfxKAqkSn?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
<hr>
<p><b>Notebook 3 (Convolutional Neural Networks (CNN)):</b> In this notebook you will learn about Convolutional Neural Networks (CNN).</p> 
<p style="color:#4863A0;"> If you want to do work with images, such as image recognition, object detection, face recognition, etc tasks CNN might be a good choice! </p>

  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1IRWaOw-7Z9VCi20udvHaKggfbxQzH1Yz?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
  <hr>
<p><b>Notebook 4 (Recurrent Neural Networks (RNN)):</b> In this nottebook you will learn about Recurrent Neural Networks (RNN).</p>
<p style="color:#4863A0;"> If you are interested in sequence modeling tasks such as prediction problems, language modelling RNNs can be a good choice!
Machine Translation. </p>

  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/12J34g2SyM-pT_vrabgQQBt_dH8Bcxu9D?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
<hr>

<p><b>Notebook 5 (Transformers):</b> In this notebook you will learn about transformer networks. Transformers are the state of the art architecture used for NLP applications and sequnce modeling.</p>
<p style="color:#4863A0;"> Transformers are similar to RNNs but can solve sequence-to-sequence tasks while handling long-range dependencies, thus more powerful than RNNs! </p>

  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1UYds1QPchIe3VfvYSk68JgmQE_3wgC6l?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
  <hr>
  
<p><b>Notebook 5 extras (BERT & GPT-2):</b> In these two notebooks you will learn how to fine-tune the two leading language models out there, BERT, and GPT-2. They are the same in that they are both based on the transformer architecture, but they are fundamentally different in that BERT has just the encoder blocks from the transformer, whilst GPT-2 has just the decoder blocks from the transformer.</p>  

<p style="color:#4863A0;"> BERT is mostly used for text classification tasks, while GPT-2 is great for text generation! Keep in mind that these models are very large in size! </p>

  <p><em> &emsp; To access the BERT example notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1nxQtQhuo_-YoqWtX9cbC21s-Rig1vRNc?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>

  
  <p><em> &emsp; To access the GPT-2 example notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1VznLN6nOVqMdZX_fmR2IvggxpflgIMeY?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
  <hr>

  
<p><b>Notebook 6 (Additional Concepts):</b> In this notebook you will learn about some methods to enhance your model architectures, and some considerations that will help boost the training (depending on the application). These topics include: Residual Networks (ResNet), dimensionality reduction, gradient clipping, learning rate warmup.</p>


  <p><em> &emsp; &emsp; To access the notebook in Google Colab <span>&#8594;</span>
    <a href="https://colab.research.google.com/drive/1MUoHtdoo2IiXkYuOO0JqM4LP8ZpeL5N7?usp=sharing">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
    </a>
  </em></p>
<hr>
